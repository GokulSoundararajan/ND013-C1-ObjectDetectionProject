{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Explore the dataset\n",
    "\n",
    "\n",
    "In this notebook, we will perform an EDA (Exploratory Data Analysis) on the processed Waymo dataset (data in the `processed` folder). In the first part, you will create a function to display "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from utils import get_dataset\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib.patches import Rectangle\r\n",
    "from PIL import Image\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset = get_dataset(\"/home/workspace/data/processed/*.tfrecord\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Write a function to display an image and the bounding boxes\n",
    "\n",
    "Implement the `display_instances` function below. This function takes a batch as an input and display an image with its corresponding bounding boxes. The only requirement is that the classes should be color coded (eg, vehicles in red, pedestrians in blue, cyclist in green)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def display_instances(dataset):\r\n",
    "    \"\"\"\r\n",
    "    This function takes a batch from the dataset and display an image with \r\n",
    "    the associated bounding boxes.\r\n",
    "\r\n",
    "    args:\r\n",
    "        - dataset[tf.Dataset] tensorflow dataset\r\n",
    "    \"\"\"\r\n",
    "    # get the batch\r\n",
    "    batch, = dataset.take(1)\r\n",
    "    \r\n",
    "    fig = plt.imshow(batch[\"image\"].numpy().astype(\"uint8\")) \r\n",
    "    colormap = {1: [1, 0, 0], 2: [0, 1, 0], 4: [0, 0, 1]}\r\n",
    "    bboxes = batch[\"groundtruth_boxes\"].numpy()\r\n",
    "    classes = batch[\"groundtruth_classes\"].numpy()\r\n",
    "    imageShape = batch[\"original_image_spatial_shape\"].numpy()\r\n",
    "    \r\n",
    "    # Fitting the bounding boxes coordinates to the image size\r\n",
    "    for cl, bb in zip(classes, bboxes):\r\n",
    "        y1, x1, y2, x2 = bb\r\n",
    "        y1 *= imageShape[0]\r\n",
    "        y2 *= imageShape[0]\r\n",
    "        x1 *= imageShape[1]\r\n",
    "        x2 *= imageShape[1]\r\n",
    "        rec = Rectangle((x1, y1), (x2-x1), (y2-y1), facecolor='none', edgecolor=colormap[cl])\r\n",
    "        # Add bboxes to the image\r\n",
    "        fig.axes.add_patch(rec)\r\n",
    "    \r\n",
    "    plt.axis(\"off\")\r\n",
    "    \r\n",
    "display_instances(dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Display 10 images \n",
    "\n",
    "Using the dataset created in the second cell and the function you just coded, display 10 random images with the associated bounding boxes. You can use the methods `take` and `shuffle` on the dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(10, 10))\r\n",
    "colormap = {1: [1, 0, 0], 2: [0, 1, 0], 4: [0, 0, 1]}\r\n",
    "\r\n",
    "for i in range(10):\r\n",
    "    data = dataset.shuffle(100, reshuffle_each_iteration=True).take(1)\r\n",
    "    for batch in data:\r\n",
    "        ax = plt.subplot(4, 3, i+1)\r\n",
    "        bboxes = batch[\"groundtruth_boxes\"].numpy()\r\n",
    "        classes = batch[\"groundtruth_classes\"].numpy()\r\n",
    "        imageShape = batch[\"original_image_spatial_shape\"].numpy()\r\n",
    "        plt.imshow(batch['image'].numpy().astype(\"uint8\"))\r\n",
    "\r\n",
    "        for cl, bb, in zip(classes, bboxes):\r\n",
    "            # Fitting the bounding boxes coordinates to the image size\r\n",
    "            y1, x1, y2, x2 = bb\r\n",
    "            y1 *= imageShape[0]\r\n",
    "            y2 *= imageShape[0]\r\n",
    "            x1 *= imageShape[1]\r\n",
    "            x2 *= imageShape[1]\r\n",
    "            rec = Rectangle((x1, y1), (x2-x1), (y2-y1), facecolor='none', edgecolor=colormap[cl])\r\n",
    "\r\n",
    "            # Add bboxes to the image\r\n",
    "            ax.add_patch(rec)\r\n",
    "\r\n",
    "            plt.axis(\"off\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Additional EDA\n",
    "\n",
    "In this last part, you are free to perform any additional analysis of the dataset. What else would like to know about the data?\n",
    "For example, think about data distribution. So far, you have only looked at a single file..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def display_chart(dataset):\r\n",
    "    \"\"\"\r\n",
    "    Takes in a dataset and displays charts to analyze its data.\r\n",
    "    \r\n",
    "    args:\r\n",
    "        - dataset[tf.Dataset] tensorflow dataset\r\n",
    "    \"\"\" \r\n",
    "\r\n",
    "    stats = {\"classIDs\": [], \"annNum\" : [] }\r\n",
    "    for record in dataset.take(10000):\r\n",
    "        stats[\"classIDs\"].extend(record[\"groundtruth_classes\"].numpy())\r\n",
    "        stats[\"annNum\"].append(len(record[\"groundtruth_classes\"].numpy()))\r\n",
    "    distribution = np.array(stats[\"classIDs\"])\r\n",
    "    distribution = np.array([(distribution == 1).sum(), (distribution == 2).sum(), (distribution == 4).sum()])  \r\n",
    "    percentages = (distribution/distribution.sum())*100\r\n",
    "    names = np.array([\"vehicle\", \"pedestrian\", \"cyclist\"])\r\n",
    "\r\n",
    "    #Bar chart for class distribution.\r\n",
    "    plt1 = plt\r\n",
    "    plt1.bar(names, percentages)\r\n",
    "    plt1.title(\"Percentages of class distribution\")\r\n",
    "    plt1.xlabel(\"Classes\")\r\n",
    "    plt1.ylabel(\"Percentages\")\r\n",
    "    plt1.show()\r\n",
    "\r\n",
    "    #Histogram for number of annotations per images\r\n",
    "    plt2 = plt\r\n",
    "    plt2.hist(stats[\"annNum\"], density=True)\r\n",
    "    plt2.title(\"Number of annotations per image\")\r\n",
    "    plt2.xlabel(\"Annotation Number\")\r\n",
    "    plt2.ylabel(\"Images\")\r\n",
    "    plt2.show()\r\n",
    "\r\n",
    "display_chart(dataset)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}